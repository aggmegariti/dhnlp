This document covers the literature related to natural language processing tasks in the context of digital humanities.

* [Neural OCR Post-Hoc Correction of Historical Corpora](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00379/100788/Neural-OCR-Post-Hoc-Correction-of-Historical) apply an RNN-based encoder-decoder to post-hoc correct OCR'ed text. Evaluation on a historical book corpus in German language showed an impressive reduction of the error rate.

* [Restoring and translating damaged Joseon Dynasty text](https://www.aclweb.org/anthology/2021.naacl-main.317) (2021) presents a multi-task learning approach to restore and translate historical documents based on a self-attention mechanism, specifically utilizing two Korean historical records, ones of the most voluminous historical records in the world. An in-depth topic-modeling-based exploratory analysis on the translated results is presented, uncovering several significant historical events.
* [Profiling of Intertextuality in Latin Literature Using Word Embeddings](https://aclanthology.org/2021.naacl-main.389.pdf) (2021) is an empirical analysis of intertextuality (identifying intertextual relationships between authors) in classical Latin literature using word embedding models. The authors curate a new dataset of 945 known parallels drawn from traditional scholarship on Latin epic poetry. They train an optimized word2vec model on a large corpus of lemmatized Latin, which achieves __state-of-the-art performance for synonym detection__ and __outperforms a widely used lexical method for intertextual search__. The authors also demonstrate that training embeddings on very small corpora can capture salient aspects of literary style. They applied this approach to replicate a previous intertextual study of the Roman historian Livy, which relied on hand-crafted stylometric features.
* [Ab Antiquo: Neural Proto-language Reconstruction](https://aclanthology.org/2021.naacl-main.353/) (2021) is a study of the automation of reconstruction of proto-words (words that several cognates are sharing). The authors provide a novel dataset for the task and show that neural sequence models outperform conventional methods applied to this task so far. Analysis of learned embeddings revealed the models learn phonologically meaningful generalizations, corresponding to well-attested phonological shifts documented by historical linguistics.
* [Restoring ancient text using deep learning: a case study on Greek epigraphy](https://arxiv.org/pdf/1910.06262.pdf) (2019) focuses on Epigraphy (the study of ancient inscribed texts, for evidence of the recorded past) and how to assist epigraphists to restore damaged inscriptions. This work presents PYTHIA, the first ancient text restoration model that recovers missing characters from a damaged text input using deep neural networks. PYTHIAâ€™s predictions achieve a 30.1% character error rate, compared to the 57.3% of human epigraphists. In 73.5% of cases the ground-truth sequence was among the Top-20 hypotheses of PYTHIA, which effectively demonstrates the impact of this assistive method on the field of digital epigraphy, and sets the state-of-the-art in ancient text restoration. 
